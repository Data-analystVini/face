# -*- coding: utf-8 -*-
"""Big mart sales prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dJ-tmQvOcJJ3Da69gOQVNai_dP7eC_eW

**importing the dependencies**
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from xgboost import XGBRegressor
from sklearn import metrics

"""**Data collection and preprocessing**"""

#loading the data from csv file to pandas Dataframe
big_mart_data=pd.read_csv('/content/Train.csv')

big_mart_data.head()

big_mart_data.shape

big_mart_data.info()

"""**Categorical Features*

*   Item_Identifier
*   Item_Fat_Content
*  Item_Type
* Outlet_Identifier
* Outlet_Size
* Outlet_Location_Type
*Outlet_Type







"""

big_mart_data.isnull().sum()

"""**Handling missing values**


Mean->average

Mode->more repeated value

"""

#mean value of Item_Weight column
big_mart_data['Item_Weight'].mean()

#filling the missing values in "Item_Weight" column with "Mean" Value
big_mart_data['Item_Weight'].fillna(big_mart_data['Item_Weight'].mean(),inplace=True)

#mode of "Outlet_Size" column
big_mart_data['Outlet_Size'].mode()

#filling the missing valuesin "Outlet_Size" column with Mode
mode_of_Outlet_size=big_mart_data.pivot_table(values='Outlet_Size',columns='Outlet_Type',aggfunc=(lambda x:x.mode()[0]))

print(mode_of_Outlet_size)

miss_values=big_mart_data['Outlet_Size'].isnull()

print(miss_values)

big_mart_data.loc[miss_values,'Outlet_Size']=big_mart_data.loc[miss_values,'Outlet_Type'].apply(lambda x:mode_of_Outlet_size[x])

#checking for missing values
big_mart_data.isnull().sum()

"""**Data Analysis**"""

big_mart_data.describe()

"""**Numerical Features**"""

sns.set()

#Item Weight distribution
plt.figure(figsize=(6,6))
sns.distplot(big_mart_data['Item_Weight'])
plt.show()

#item Visibility distribution
plt.figure(figsize=(6,6))
sns.distplot(big_mart_data['Item_Visibility'])
plt.show()

#item MRP distribution
plt.figure(figsize=(6,6))
sns.distplot(big_mart_data['Item_MRP'])
plt.show()

#Item_Outlet_Sales distribution
plt.figure(figsize=(6,6))
sns.distplot(big_mart_data['Item_Outlet_Sales'])
plt.show()

#Outlet_Establishment_Year distribution
plt.figure(figsize=(6,6))
sns.countplot(x='Outlet_Establishment_Year',data=big_mart_data)
plt.show()

"""**Categorical Features**"""

#Item_Fat_Content column
plt.figure(figsize=(6,6))
sns.countplot(x='Item_Fat_Content',data=big_mart_data)
plt.show()

#Item_Type column
plt.figure(figsize=(30,6))
sns.countplot(x='Item_Type',data=big_mart_data)
plt.show()

#Outlet_Size column
plt.figure(figsize=(30,6))
sns.countplot(x='Outlet_Size',data=big_mart_data)
plt.show()

"""Data pre-processing"""

big_mart_data.tail()

big_mart_data['Item_Fat_Content'].value_counts()

big_mart_data.replace({'Item_Fat_Content':{'low fat':'Low Fat','LF':'Low Fat','reg':'Regular'}},inplace=True)

big_mart_data['Item_Fat_Content'].value_counts()

"""**Label encoding**"""

encoder=LabelEncoder()

big_mart_data['Item_Identifier']=encoder.fit_transform(big_mart_data['Item_Identifier'])
big_mart_data['Item_Fat_Content']=encoder.fit_transform(big_mart_data['Item_Fat_Content'])
big_mart_data['Item_Type']=encoder.fit_transform(big_mart_data['Item_Type'])
big_mart_data['Outlet_Identifier']=encoder.fit_transform(big_mart_data['Outlet_Identifier'])
big_mart_data['Outlet_Size']=encoder.fit_transform(big_mart_data['Outlet_Size'])
big_mart_data['Outlet_Location_Type']=encoder.fit_transform(big_mart_data['Outlet_Location_Type'])
big_mart_data['Outlet_Type']=encoder.fit_transform(big_mart_data['Outlet_Type'])

big_mart_data.head()

"""**Splitting featues and Target**"""

X=big_mart_data.drop(columns='Item_Outlet_Sales',axis=1)
Y=big_mart_data['Item_Outlet_Sales']

big_mart_data.head()

print(X)

print(Y)

"""**Splitting the data into Training data & Testing Data**"""

X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=2)

print(X.shape,X_train.shape,X_test.shape)

"""**Machine Learning Model Training**

**XGBOOST Regressor**
"""

regressor=XGBRegressor()

regressor.fit(X_train,Y_train)

"""**Evaluating**"""

#prediction on training data
training_data_prediction=regressor.predict(X_train)

# Rsquared value
r2_train=metrics.r2_score(Y_train,training_data_prediction)

print('R squared value:',r2_train)

#prediction on test data
test_data_prediction=regressor.predict(X_test)

#r squared value
r2_test=metrics.r2_score(Y_test,test_data_prediction)

print('R squared value:',r2_test)

Y_test=list(Y_test)

plt.plot(Y_test,color='blue',label='Actual Price')
plt.plot(test_data_prediction,color='green',label='Predicted Price')
plt.title('Predicted V/s Actual Sales ')
plt.xlabel('Actual values')
plt.ylabel('Sales Price')
plt.legend()
plt.show()

big_mart_data.tail()

input_data=(370,	6.865	,0,	0.056783,	13	,214.5218,	1,	1987,	0,	2,	1	)
input_data_as_numpy_array=np.array(input_data)
reshaped=input_data_as_numpy_array.reshape(1,-1)
prediction=regressor.predict(reshaped)
print('Predicted Sales Price:',prediction[0])